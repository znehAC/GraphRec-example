{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "from utils.graphrec import GraphRec, get_data100k\n",
    "from utils.metrics import queries_ndcg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "logging.getLogger('tensorflow').disabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " Para treinar o modelo carregamos o dataset que contem os id's de usuario e de item e o rating de cada relacao,\n",
    " Para utilizar as features de usuario e de item o loading delas é feita no proprio código do graphrec.\n",
    " Essa funcao carrega os dados e separa em 90% para treino e 10% de teste.\n",
    "'''\n",
    "df_train, df_test = get_data100k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " Treinando o modelo podemos selecionar se vai ser usado dados do usuario e de item, e se vai utilizar da tecnica\n",
    " das features de graph, dependendo da escolha utilizada os hyper-parametros devem ser atualizados.\n",
    " Para utilizar outro dataset deve-se mudar o parametro Dataset, e incluir no codigo o carregamento das\n",
    " features externas\n",
    "'''\n",
    "model = GraphRec(df_train, df_test, ItemData= False, UserData = False, Graph=False, Dataset='100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " Para avaliação do modelo foi separado os ids dos usuarios como id de consultas e o score real\n",
    "'''\n",
    "df_test = df_test.sort_values('user')\n",
    "qids = df_test['user']\n",
    "y_test = df_test['rate']\n",
    "predictions = np.array(model.predict(df_test)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " Os metodos de avaliações escolhidos são a média de ndcg das consultas e o rmse, resultados podem\n",
    " ser vistos abaixo.\n",
    "'''\n",
    "ndcgs = queries_ndcg(y_test, predictions, qids)\n",
    "print(\"mean ndcg:\", ndcgs.mean())\n",
    "rmse = mean_squared_error(y_test, predictions, squared = False)\n",
    "print(\"rmse:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    sem graph features com external features\n",
    "    mean ndcg: 0.8944496166257601\n",
    "    rmse: 0.8958193504345224\n",
    "\n",
    "    sem graph features sem external features\n",
    "    mean ndcg: 0.8910245956442313\n",
    "    rmse: 0.8935640035558002\n",
    "\n",
    "    com graph features com external features\n",
    "    mean ndcg: 0.8985257081563411\n",
    "    rmse: 0.8853696390671398\n",
    "\n",
    "    com graph features sem external features\n",
    "    mean ndcg: 0.8977134940003574\n",
    "    rmse: 0.8990311527796113"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "438c68fb6f46a0fb0cfe7ba661695ada31d7977d84f2101954b64fefe016c871"
  },
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
